{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### messages_to_history, stream_graph, random_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "def get_role_from_messages(msg):\n",
    "    if isinstance(msg, HumanMessage):\n",
    "        return \"user\"\n",
    "    elif isinstance(msg, AIMessage):\n",
    "        return \"assistant\"\n",
    "    else:\n",
    "        return \"assistant\"\n",
    "\n",
    "\n",
    "def messages_to_history(messages):\n",
    "    return \"\\n\".join(\n",
    "        [f\"{get_role_from_messages(msg)}: {msg.content}\" for msg in messages]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "\n",
    "\n",
    "def stream_graph(\n",
    "    graph: CompiledStateGraph,\n",
    "    inputs: dict,\n",
    "    config: RunnableConfig,\n",
    "    node_names: List[str] = [],\n",
    "    callback: Callable = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    LangGraphì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        graph (CompiledStateGraph): ì‹¤í–‰í•  ì»´íŒŒì¼ëœ LangGraph ê°ì²´\n",
    "        inputs (dict): ê·¸ë˜í”„ì— ì „ë‹¬í•  ì…ë ¥ê°’ ë”•ì…”ë„ˆë¦¬\n",
    "        config (RunnableConfig): ì‹¤í–‰ ì„¤ì •\n",
    "        node_names (List[str], optional): ì¶œë ¥í•  ë…¸ë“œ ì´ë¦„ ëª©ë¡. ê¸°ë³¸ê°’ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸\n",
    "        callback (Callable, optional): ê° ì²­í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜. ê¸°ë³¸ê°’ì€ None\n",
    "            ì½œë°± í•¨ìˆ˜ëŠ” {\"node\": str, \"content\": str} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤.\n",
    "\n",
    "    Returns:\n",
    "        None: í•¨ìˆ˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ì¶œë ¥ë§Œ í•˜ê³  ë°˜í™˜ê°’ì€ ì—†ìŠµë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    prev_node = \"\"\n",
    "    for chunk_msg, metadata in graph.stream(inputs, config, stream_mode=\"messages\"):\n",
    "        curr_node = metadata[\"langgraph_node\"]\n",
    "\n",
    "        # node_namesê°€ ë¹„ì–´ìˆê±°ë‚˜ í˜„ì¬ ë…¸ë“œê°€ node_namesì— ìˆëŠ” ê²½ìš°ì—ë§Œ ì²˜ë¦¬\n",
    "        if not node_names or curr_node in node_names:\n",
    "            # ì½œë°± í•¨ìˆ˜ê°€ ìˆëŠ” ê²½ìš° ì‹¤í–‰\n",
    "            if callback:\n",
    "                callback({\"node\": curr_node, \"content\": chunk_msg.content})\n",
    "            # ì½œë°±ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶œë ¥\n",
    "            else:\n",
    "                # ë…¸ë“œê°€ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ êµ¬ë¶„ì„  ì¶œë ¥\n",
    "                if curr_node != prev_node:\n",
    "                    print(\"\\n\" + \"=\" * 50)\n",
    "                    print(f\"ğŸ”„ Node: \\033[1;36m{curr_node}\\033[0m ğŸ”„\")\n",
    "                    print(\"- \" * 25)\n",
    "                print(chunk_msg.content, end=\"\", flush=True)\n",
    "\n",
    "            prev_node = curr_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def random_uuid():\n",
    "    return str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from operator import itemgetter\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "class RetrievalChain(ABC):\n",
    "    def __init__(self):\n",
    "        self.source_uri = None\n",
    "        self.k = 10\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_documents(self, source_uris):\n",
    "        \"\"\"loaderë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_text_splitter(self):\n",
    "        \"\"\"text splitterë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def split_documents(self, docs, text_splitter):\n",
    "        \"\"\"text splitterë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë¶„í• í•©ë‹ˆë‹¤.\"\"\"\n",
    "        return text_splitter.split_documents(docs)\n",
    "\n",
    "    def create_embedding(self):\n",
    "        return OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "    def create_vectorstore(self, split_docs):\n",
    "        return FAISS.from_documents(\n",
    "            documents=split_docs, embedding=self.create_embedding()\n",
    "        )\n",
    "\n",
    "    def create_retriever(self, vectorstore):\n",
    "        # MMRì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” retrieverë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        dense_retriever = vectorstore.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": self.k}\n",
    "        )\n",
    "        return dense_retriever\n",
    "\n",
    "    def create_model(self):\n",
    "        return ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    def create_prompt(self):\n",
    "        return hub.pull(\"teddynote/rag-prompt-chat-history\")\n",
    "\n",
    "    @staticmethod\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\".join(docs)\n",
    "\n",
    "    def create_chain(self):\n",
    "        docs = self.load_documents(self.source_uri)\n",
    "        text_splitter = self.create_text_splitter()\n",
    "        split_docs = self.split_documents(docs, text_splitter)\n",
    "        self.vectorstore = self.create_vectorstore(split_docs)\n",
    "        self.retriever = self.create_retriever(self.vectorstore)\n",
    "        model = self.create_model()\n",
    "        prompt = self.create_prompt()\n",
    "        self.chain = (\n",
    "            {\n",
    "                \"question\": itemgetter(\"question\"),\n",
    "                \"context\": itemgetter(\"context\"),\n",
    "                \"chat_history\": itemgetter(\"chat_history\"),\n",
    "            }\n",
    "            | prompt\n",
    "            | model\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "class PDFRetrievalChain(RetrievalChain):\n",
    "    def __init__(self, source_uri: Annotated[str, \"Source URI\"]):\n",
    "        self.source_uri = source_uri\n",
    "        self.k = 10\n",
    "\n",
    "    def load_documents(self, source_uris: List[str]):\n",
    "        docs :List[Document]= []\n",
    "        for source_uri in source_uris:\n",
    "            loader = PDFPlumberLoader(source_uri)\n",
    "            docs.extend(loader.load())\n",
    "\n",
    "        return docs\n",
    "\n",
    "    def create_text_splitter(self):\n",
    "        return RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = PDFRetrievalChain([\"*.pdf\"]).create_chain()\n",
    "\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            f\"<document><content>{doc.page_content}</content><source>{doc.metadata['source']}</source><page>{int(doc.metadata['page'])+1}</page></document>\"\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
